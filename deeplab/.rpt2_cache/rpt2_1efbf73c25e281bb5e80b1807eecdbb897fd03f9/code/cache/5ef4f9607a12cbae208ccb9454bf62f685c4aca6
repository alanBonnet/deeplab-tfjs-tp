{"code":"/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport * as tslib_1 from \"tslib\";\r\nimport * as tfconv from '@tensorflow/tfjs-converter';\r\nimport * as tf from '@tensorflow/tfjs-core';\r\nimport { getColormap, getLabels, getURL, toInputTensor, toSegmentationImage } from './utils';\r\nexport { version } from './version';\r\nexport { getColormap, getLabels, getURL, toSegmentationImage };\r\n/**\r\n * Initializes the DeepLab model and returns a `SemanticSegmentation` object.\r\n *\r\n * @param input ::\r\n *     `ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement`\r\n *\r\n *  The input image to feed through the network.\r\n *\r\n * @param config :: `ModelConfig`\r\n *\r\n * The configuration for the model with any of the following attributes:\r\n *\r\n *   * quantizationBytes (optional) :: `QuantizationBytes`\r\n *\r\n *      The degree to which weights are quantized (either 1, 2 or 4).\r\n *      Setting this attribute to 1 or 2 will load the model with int32 and\r\n *      float32 compressed to 1 or 2 bytes respectively.\r\n *      Set it to 4 to disable quantization.\r\n *\r\n *   * base (optional) :: `ModelArchitecture`\r\n *\r\n *      The type of model to load (either `pascal`, `cityscapes` or `ade20k`).\r\n *\r\n *   * modelUrl (optional) :: `string`\r\n *\r\n *      The URL from which to load the TF.js GraphModel JSON.\r\n *      Inferred from `base` and `quantizationBytes` if undefined.\r\n *\r\n * @return The initialized `SemanticSegmentation` object\r\n */\r\nexport function load(modelConfig) {\r\n    if (modelConfig === void 0) { modelConfig = {\r\n        base: 'pascal',\r\n        quantizationBytes: 2\r\n    }; }\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var graphModel, deeplab;\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    if (tf == null) {\r\n                        throw new Error(\"Cannot find TensorFlow.js.\" +\r\n                            \" If you are using a <script> tag, please \" +\r\n                            \"also include @tensorflow/tfjs on the page before using this model.\");\r\n                    }\r\n                    if (modelConfig.base) {\r\n                        if (['pascal', 'cityscapes', 'ade20k'].indexOf(modelConfig.base) === -1) {\r\n                            throw new Error(\"SemanticSegmentation cannot be constructed \" +\r\n                                (\"with an invalid base model \" + modelConfig.base + \". \") +\r\n                                \"Try one of 'pascal', 'cityscapes' and 'ade20k'.\");\r\n                        }\r\n                        if ([1, 2, 4].indexOf(modelConfig.quantizationBytes) === -1) {\r\n                            throw new Error(\"Only quantization to 1, 2 or 4 bytes is supported.\");\r\n                        }\r\n                    }\r\n                    else if (!modelConfig.modelUrl) {\r\n                        throw new Error(\"SemanticSegmentation can be constructed either by passing \" +\r\n                            \"the weights URL or one of the supported base model names from \" +\r\n                            \"'pascal', 'cityscapes' and 'ade20k',\" +\r\n                            \"together with the degree of quantization (either 1, 2 or 4).\" +\r\n                            \"Aborting, since neither has been provided.\");\r\n                    }\r\n                    return [4 /*yield*/, tfconv.loadGraphModel(modelConfig.modelUrl ||\r\n                            getURL(modelConfig.base, modelConfig.quantizationBytes))];\r\n                case 1:\r\n                    graphModel = _a.sent();\r\n                    deeplab = new SemanticSegmentation(graphModel, modelConfig.base);\r\n                    return [2 /*return*/, deeplab];\r\n            }\r\n        });\r\n    });\r\n}\r\nvar SemanticSegmentation = /** @class */ (function () {\r\n    function SemanticSegmentation(graphModel, base) {\r\n        this.model = graphModel;\r\n        this.base = base;\r\n    }\r\n    /**\r\n     * Segments an arbitrary image and generates a two-dimensional tensor with\r\n     * class labels assigned to each cell of the grid overlayed on the image ( the\r\n     * maximum number of cells on the side is fixed to 513).\r\n     *\r\n     * @param input ::\r\n     *     `ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement`\r\n     *\r\n     * The input image to segment.\r\n     *\r\n     * @return rawSegmentationMap :: `tf.Tensor2D`\r\n     *\r\n     * The segmentation map of the image\r\n     */\r\n    SemanticSegmentation.prototype.predict = function (input) {\r\n        var _this = this;\r\n        return tf.tidy(function () {\r\n            var data = tf.cast(toInputTensor(input), 'int32');\r\n            return tf.squeeze(_this.model.execute(data));\r\n        });\r\n    };\r\n    /**\r\n     * Segments an arbitrary image and generates a two-dimensional tensor with\r\n     * class labels assigned to each cell of the grid overlayed on the image ( the\r\n     * maximum number of cells on the side is fixed to 513).\r\n     *\r\n     * @param image :: `ImageData | HTMLImageElement | HTMLCanvasElement |\r\n     * HTMLVideoElement | tf.Tensor3D`;\r\n     *\r\n     *   The image to segment\r\n     *\r\n     * @param config (optional) The configuration object for the segmentation:\r\n     *\r\n     * - **config.canvas** (optional) :: `HTMLCanvasElement`\r\n     *\r\n     *   The canvas where to draw the output\r\n     *\r\n     * - **config.colormap** (optional) :: `[number, number, number][]`\r\n     *\r\n     *   The array of RGB colors corresponding to labels\r\n     *\r\n     * - **config.labels** (optional) :: `string[]`\r\n     *\r\n     *   The array of names corresponding to labels\r\n     *\r\n     *   By [default](./src/index.ts#L81), `colormap` and `labels` are set\r\n     * according to the `base` model attribute passed during initialization.\r\n     *\r\n     * @returns A promise of a `DeepLabOutput` object, with four attributes:\r\n     *\r\n     * - **legend** :: `{ [name: string]: [number, number, number] }`\r\n     *\r\n     *   The legend is a dictionary of objects recognized in the image and their\r\n     *   colors in RGB format.\r\n     *\r\n     * - **height** :: `number`\r\n     *\r\n     *   The height of the returned segmentation map\r\n     *\r\n     * - **width** :: `number`\r\n     *\r\n     *   The width of the returned segmentation map\r\n     *\r\n     * - **segmentationMap** :: `Uint8ClampedArray`\r\n     *\r\n     *   The colored segmentation map as `Uint8ClampedArray` which can be\r\n     *   fed into `ImageData` and mapped to a canvas.\r\n     */\r\n    SemanticSegmentation.prototype.segment = function (input, config) {\r\n        if (config === void 0) { config = {}; }\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var colormap, labels, canvas, rawSegmentationMap, _a, height, width, _b, legend, segmentationMap;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_c) {\r\n                switch (_c.label) {\r\n                    case 0:\r\n                        if (!((config.colormap && config.labels) || this.base)) {\r\n                            throw new Error(\"Calling the 'segment' method requires either the 'base'\" +\r\n                                \" attribute to be defined \" +\r\n                                \"(e.g. 'pascal', 'cityscapes' or'ade20k'),\" +\r\n                                \" or 'colormap' and 'labels' options to be set. \" +\r\n                                \"Aborting, since neither has been provided.\");\r\n                        }\r\n                        else if (!(config.colormap && config.labels)) {\r\n                            config.colormap = getColormap(this.base);\r\n                            config.labels = getLabels(this.base);\r\n                        }\r\n                        colormap = config.colormap, labels = config.labels, canvas = config.canvas;\r\n                        rawSegmentationMap = tf.tidy(function () { return _this.predict(input); });\r\n                        _a = rawSegmentationMap.shape, height = _a[0], width = _a[1];\r\n                        return [4 /*yield*/, toSegmentationImage(colormap, labels, rawSegmentationMap, canvas)];\r\n                    case 1:\r\n                        _b = _c.sent(), legend = _b.legend, segmentationMap = _b.segmentationMap;\r\n                        tf.dispose(rawSegmentationMap);\r\n                        return [2 /*return*/, { legend: legend, height: height, width: width, segmentationMap: segmentationMap }];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    /**\r\n     * Dispose of the tensors allocated by the model.\r\n     * You should call this when you are done with the model.\r\n     */\r\n    SemanticSegmentation.prototype.dispose = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            return tslib_1.__generator(this, function (_a) {\r\n                if (this.model) {\r\n                    this.model.dispose();\r\n                }\r\n                return [2 /*return*/];\r\n            });\r\n        });\r\n    };\r\n    return SemanticSegmentation;\r\n}());\r\nexport { SemanticSegmentation };\r\n//# sourceMappingURL=index.js.map","references":["C:/Users/Alan Bonnet/Desktop/Clasess/tensor/Trabajo grpal/TODOS_LOS_MODELOS/tfjs-models/deeplab/node_modules/@tensorflow/tfjs-converter/dist/index.d.ts","C:/Users/Alan Bonnet/Desktop/Clasess/tensor/Trabajo grpal/TODOS_LOS_MODELOS/tfjs-models/deeplab/node_modules/@tensorflow/tfjs-core/dist/index.d.ts","C:/Users/Alan Bonnet/Desktop/Clasess/tensor/Trabajo grpal/TODOS_LOS_MODELOS/tfjs-models/deeplab/src/types.ts","C:/Users/Alan Bonnet/Desktop/Clasess/tensor/Trabajo grpal/TODOS_LOS_MODELOS/tfjs-models/deeplab/src/utils.ts","C:/Users/Alan Bonnet/Desktop/Clasess/tensor/Trabajo grpal/TODOS_LOS_MODELOS/tfjs-models/deeplab/src/version.ts"],"map":"{\"version\":3,\"file\":\"index.js\",\"sourceRoot\":\"\",\"sources\":[\"../../src/index.ts\"],\"names\":[],\"mappings\":\"AAAA;;;;;;;;;;;;;;;GAeG;;AAEH,OAAO,KAAK,MAAM,MAAM,4BAA4B,CAAC;AACrD,OAAO,KAAK,EAAE,MAAM,uBAAuB,CAAC;AAG5C,OAAO,EAAC,WAAW,EAAE,SAAS,EAAE,MAAM,EAAE,aAAa,EAAE,mBAAmB,EAAC,MAAM,SAAS,CAAC;AAE3F,OAAO,EAAC,OAAO,EAAC,MAAM,WAAW,CAAC;AAClC,OAAO,EACL,WAAW,EACX,SAAS,EACT,MAAM,EAGN,mBAAmB,EACpB,CAAC;AAEF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA6BG;AACH,MAAM,UAAgB,IAAI,CACtB,WAGC;IAHD,4BAAA,EAAA;QACE,IAAI,EAAE,QAAQ;QACd,iBAAiB,EAAE,CAAC;KACrB;;;;;;oBAEH,IAAI,EAAE,IAAI,IAAI,EAAE;wBACd,MAAM,IAAI,KAAK,CACX,4BAA4B;4BAC5B,2CAA2C;4BAC3C,oEAAoE,CAAC,CAAC;qBAC3E;oBACD,IAAI,WAAW,CAAC,IAAI,EAAE;wBACpB,IAAI,CAAC,QAAQ,EAAE,YAAY,EAAE,QAAQ,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE;4BACvE,MAAM,IAAI,KAAK,CACX,6CAA6C;iCAC7C,gCAA8B,WAAW,CAAC,IAAI,OAAI,CAAA;gCAClD,iDAAiD,CAAC,CAAC;yBACxD;wBACD,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,iBAAiB,CAAC,KAAK,CAAC,CAAC,EAAE;4BAC3D,MAAM,IAAI,KAAK,CAAC,oDAAoD,CAAC,CAAC;yBACvE;qBACF;yBAAM,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE;wBAChC,MAAM,IAAI,KAAK,CACX,4DAA4D;4BAC5D,gEAAgE;4BAChE,sCAAsC;4BACtC,8DAA8D;4BAC9D,4CAA4C,CAAC,CAAC;qBACnD;oBAEkB,qBAAM,MAAM,CAAC,cAAc,CAC1C,WAAW,CAAC,QAAQ;4BACpB,MAAM,CAAC,WAAW,CAAC,IAAI,EAAE,WAAW,CAAC,iBAAiB,CAAC,CAAC,EAAA;;oBAFtD,UAAU,GAAG,SAEyC;oBACtD,OAAO,GAAG,IAAI,oBAAoB,CAAC,UAAU,EAAE,WAAW,CAAC,IAAI,CAAC,CAAC;oBACvE,sBAAO,OAAO,EAAC;;;;CAChB;AAED;IAGE,8BACI,UAA6B,EAC7B,IAAwB;QAE1B,IAAI,CAAC,KAAK,GAAG,UAAU,CAAC;QACxB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;IACnB,CAAC;IAED;;;;;;;;;;;;;OAaG;IACI,sCAAO,GAAd,UAAe,KAAmB;QAAlC,iBAKC;QAJC,OAAO,EAAE,CAAC,IAAI,CAAC;YACb,IAAM,IAAI,GAAG,EAAE,CAAC,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,EAAE,OAAO,CAAC,CAAC;YACpD,OAAO,EAAE,CAAC,OAAO,CAAC,KAAI,CAAC,KAAK,CAAC,OAAO,CAAC,IAAI,CAAc,CAAC,CAAC;QAC3D,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OA8CG;IAEU,sCAAO,GAApB,UAAqB,KAAmB,EAAE,MAA6B;QAA7B,uBAAA,EAAA,WAA6B;;;;;;;wBAErE,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,QAAQ,IAAI,MAAM,CAAC,MAAM,CAAC,IAAI,IAAI,CAAC,IAAI,CAAC,EAAE;4BACtD,MAAM,IAAI,KAAK,CACX,yDAAyD;gCACzD,2BAA2B;gCAC3B,2CAA2C;gCAC3C,iDAAiD;gCACjD,4CAA4C,CAAC,CAAC;yBACnD;6BAAM,IAAI,CAAC,CAAC,MAAM,CAAC,QAAQ,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE;4BAC9C,MAAM,CAAC,QAAQ,GAAG,WAAW,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;4BACzC,MAAM,CAAC,MAAM,GAAG,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;yBACtC;wBAEM,QAAQ,GAAoB,MAAM,SAA1B,EAAE,MAAM,GAAY,MAAM,OAAlB,EAAE,MAAM,GAAI,MAAM,OAAV,CAAW;wBACpC,kBAAkB,GAAG,EAAE,CAAC,IAAI,CAAC,cAAM,OAAA,KAAI,CAAC,OAAO,CAAC,KAAK,CAAC,EAAnB,CAAmB,CAAC,CAAC;wBAExD,KAAkB,kBAAkB,CAAC,KAAK,EAAzC,MAAM,QAAA,EAAE,KAAK,QAAA,CAA6B;wBAE7C,qBAAM,mBAAmB,CAAC,QAAQ,EAAE,MAAM,EAAE,kBAAkB,EAAE,MAAM,CAAC,EAAA;;wBADrE,KACF,SAAuE,EADpE,MAAM,YAAA,EAAE,eAAe,qBAAA;wBAG9B,EAAE,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC;wBAE/B,sBAAO,EAAC,MAAM,QAAA,EAAE,MAAM,QAAA,EAAE,KAAK,OAAA,EAAE,eAAe,iBAAA,EAAC,EAAC;;;;KACjD;IAED;;;OAGG;IAEU,sCAAO,GAApB;;;gBACE,IAAI,IAAI,CAAC,KAAK,EAAE;oBACd,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE,CAAC;iBACtB;;;;KACF;IACH,2BAAC;AAAD,CAAC,AApHD,IAoHC\"}","dts":{"name":"C:/Users/Alan Bonnet/Desktop/Clasess/tensor/Trabajo grpal/TODOS_LOS_MODELOS/tfjs-models/deeplab/index.d.ts","writeByteOrderMark":false,"text":"/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\nimport * as tfconv from '@tensorflow/tfjs-converter';\r\nimport * as tf from '@tensorflow/tfjs-core';\r\nimport { DeepLabInput, DeepLabOutput, ModelArchitecture, ModelConfig, PredictionConfig } from './types';\r\nimport { getColormap, getLabels, getURL, toSegmentationImage } from './utils';\r\nexport { version } from './version';\r\nexport { getColormap, getLabels, getURL, ModelConfig, PredictionConfig, toSegmentationImage };\r\n/**\r\n * Initializes the DeepLab model and returns a `SemanticSegmentation` object.\r\n *\r\n * @param input ::\r\n *     `ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement`\r\n *\r\n *  The input image to feed through the network.\r\n *\r\n * @param config :: `ModelConfig`\r\n *\r\n * The configuration for the model with any of the following attributes:\r\n *\r\n *   * quantizationBytes (optional) :: `QuantizationBytes`\r\n *\r\n *      The degree to which weights are quantized (either 1, 2 or 4).\r\n *      Setting this attribute to 1 or 2 will load the model with int32 and\r\n *      float32 compressed to 1 or 2 bytes respectively.\r\n *      Set it to 4 to disable quantization.\r\n *\r\n *   * base (optional) :: `ModelArchitecture`\r\n *\r\n *      The type of model to load (either `pascal`, `cityscapes` or `ade20k`).\r\n *\r\n *   * modelUrl (optional) :: `string`\r\n *\r\n *      The URL from which to load the TF.js GraphModel JSON.\r\n *      Inferred from `base` and `quantizationBytes` if undefined.\r\n *\r\n * @return The initialized `SemanticSegmentation` object\r\n */\r\nexport declare function load(modelConfig?: ModelConfig): Promise<SemanticSegmentation>;\r\nexport declare class SemanticSegmentation {\r\n    readonly model: tfconv.GraphModel;\r\n    readonly base: ModelArchitecture;\r\n    constructor(graphModel: tfconv.GraphModel, base?: ModelArchitecture);\r\n    /**\r\n     * Segments an arbitrary image and generates a two-dimensional tensor with\r\n     * class labels assigned to each cell of the grid overlayed on the image ( the\r\n     * maximum number of cells on the side is fixed to 513).\r\n     *\r\n     * @param input ::\r\n     *     `ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement`\r\n     *\r\n     * The input image to segment.\r\n     *\r\n     * @return rawSegmentationMap :: `tf.Tensor2D`\r\n     *\r\n     * The segmentation map of the image\r\n     */\r\n    predict(input: DeepLabInput): tf.Tensor2D;\r\n    /**\r\n     * Segments an arbitrary image and generates a two-dimensional tensor with\r\n     * class labels assigned to each cell of the grid overlayed on the image ( the\r\n     * maximum number of cells on the side is fixed to 513).\r\n     *\r\n     * @param image :: `ImageData | HTMLImageElement | HTMLCanvasElement |\r\n     * HTMLVideoElement | tf.Tensor3D`;\r\n     *\r\n     *   The image to segment\r\n     *\r\n     * @param config (optional) The configuration object for the segmentation:\r\n     *\r\n     * - **config.canvas** (optional) :: `HTMLCanvasElement`\r\n     *\r\n     *   The canvas where to draw the output\r\n     *\r\n     * - **config.colormap** (optional) :: `[number, number, number][]`\r\n     *\r\n     *   The array of RGB colors corresponding to labels\r\n     *\r\n     * - **config.labels** (optional) :: `string[]`\r\n     *\r\n     *   The array of names corresponding to labels\r\n     *\r\n     *   By [default](./src/index.ts#L81), `colormap` and `labels` are set\r\n     * according to the `base` model attribute passed during initialization.\r\n     *\r\n     * @returns A promise of a `DeepLabOutput` object, with four attributes:\r\n     *\r\n     * - **legend** :: `{ [name: string]: [number, number, number] }`\r\n     *\r\n     *   The legend is a dictionary of objects recognized in the image and their\r\n     *   colors in RGB format.\r\n     *\r\n     * - **height** :: `number`\r\n     *\r\n     *   The height of the returned segmentation map\r\n     *\r\n     * - **width** :: `number`\r\n     *\r\n     *   The width of the returned segmentation map\r\n     *\r\n     * - **segmentationMap** :: `Uint8ClampedArray`\r\n     *\r\n     *   The colored segmentation map as `Uint8ClampedArray` which can be\r\n     *   fed into `ImageData` and mapped to a canvas.\r\n     */\r\n    segment(input: DeepLabInput, config?: PredictionConfig): Promise<DeepLabOutput>;\r\n    /**\r\n     * Dispose of the tensors allocated by the model.\r\n     * You should call this when you are done with the model.\r\n     */\r\n    dispose(): Promise<void>;\r\n}\r\n"}}
